{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z-–∏–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "\n",
    "–î–æ–ø—É—Å—Ç–∏–º, –Ω–∞–º –æ—Ç–∫—É–¥–∞-—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–æ, —á—Ç–æ –¥–∏—Å–ø–µ—Ä—Å–∏—è auc_scores $\\sigma^2=0.25$. –ü–æ—Å—Ç—Ä–æ–∏–º –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –≤–∏–¥–∞ $$\\bar{X}_n \\pm z_{1-\\frac{\\alpha}{2}} \\frac{\\sigma}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"95%% confidence interval\", _zconfint_generic(mean,sqrt(0.25/n), alpha = 0.05, 'two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-–∏–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "\n",
    "–í–º–µ—Å—Ç–æ –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏ $\\sigma^2$, –∫–æ—Ç–æ—Ä—É—é –º—ã –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –Ω–µ –∑–Ω–∞–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±–æ—Ä–æ—á–Ω—ã–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏, –∏ –ø–æ—Å—Ç—Ä–æ–∏–º –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –≤–∏–¥–∞ $$\\bar{X}_n \\pm t_{1-\\frac{\\alpha}{2}} \\frac{S}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"mean 95%% confidence interval\", _tconfint_generic(mean, std/sqrt(n), dof= n - 1, alpha=0.05, 'two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –¥–æ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "\n",
    "$$\\hat{p}\\pm z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}\\left(1-\\hat{p}\\right)}{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_interval = proportion_confint(sum(sample), len(sample), method = 'normal')\n",
    "print 'normal_interval [%f, %f]' % (normal_interval[0], normal_interval[1]) \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –£–∏–ª—Å–æ–Ω–∞\n",
    "\n",
    "$$\\frac1{ 1 + \\frac{z^2}{n} } \\left( \\hat{p} + \\frac{z^2}{2n} \\pm z \\sqrt{ \\frac{ \\hat{p}\\left(1-\\hat{p}\\right)}{n} + \\frac{\n",
    "z^2}{4n^2} } \\right), \\;\\; z \\equiv z_{1-\\frac{\\alpha}{2}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilson_interval = proportion_confint(sum(sample), len(sample), method = 'wilson')\n",
    "print 'wilson_interval [%f, %f]' % (wilson_interval[0], wilson_interval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –∑–∞–¥–∞–Ω–Ω–æ–π —à–∏—Ä–∏–Ω—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import samplesize_confint_proportion\n",
    "import numpy as np\n",
    "n_samples = int(np.ceil(samplesize_confint_proportion(sample.mean(), width/2)))\n",
    "# n_samples - —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏\n",
    "# width - —à–∏—Ä–∏–Ω–∞ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –¥–≤—É—Ö –¥–æ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.weightstats import *\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ –¥–æ–ª–µ–π (–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –≤—ã–±–æ—Ä–∫–∏)\n",
    "\n",
    " $..$ | $X_1$ | $X_2$  \n",
    " ------------- | ------------- | -------------|\n",
    "  1  | a | b \n",
    "  0  | c | d \n",
    "  $\\sum$ | $n_1$| $n_2$\n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{a}{n_1}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{b}{n_2}$$\n",
    "\n",
    "\n",
    "$$\\text{–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è }p_1 - p_2\\colon \\;\\; \\hat{p}_1 - \\hat{p}_2 \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_confint_diff_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)   \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)\n",
    "print \"confidence interval: [%f, %f]\" % proportions_confint_diff_ind(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ –¥–æ–ª–µ–π (—Å–≤—è–∑–∞–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏)\n",
    "\n",
    "$X_1$ \\ $X_2$ | 1| 0 | $\\sum$\n",
    "  ------------- | -------------| -------------| -------------|\n",
    "  1  | e | f | e + f\n",
    "  0  | g | h | g + h\n",
    "  $\\sum$ | e + g| f + h | n  \n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{e + f}{n}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{e + g}{n}$$\n",
    "\n",
    "$$ \\hat{p}_1 - \\hat{p}_2 = \\frac{f - g}{n}$$\n",
    "\n",
    "\n",
    "$$\\text{–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è }p_1 - p_2\\colon \\;\\;  \\frac{f - g}{n} \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{f + g}{n^2} - \\frac{(f - g)^2}{n^3}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_confint_diff_rel(sample1, sample2, alpha = 0.05):\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    sample = zip(sample1, sample2)\n",
    "    n = len(sample)\n",
    "        \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    left_boundary = float(f - g) / n  - z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    right_boundary = float(f - g) / n  + z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    return (left_boundary, right_boundary)\n",
    "print \"confidence interval: [%f, %f]\" % proportions_confint_diff_rel(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples): #—Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ n_samples –≤—ã–±–æ—Ä–æ–∫ –∏–∑ data, –º–µ—Ç–æ–¥–æ–º bootstrap\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "def stat_intervals(stat, alpha): #—Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å–∏–∫–∏\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_def_age = map(np.median, get_bootstrap_samples(df[df.default == 0].AGE.values, 1000)) #–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—ã–±–æ—Ä–∫–∏ –∏ –Ω–∞—Ö–æ–¥–∏–º –º–µ–¥–∏–∞–Ω—ã\n",
    "with_def_age = map(np.median, get_bootstrap_samples(df[df.default == 1].AGE.values, 1000))\n",
    "\n",
    "print 'no_def_age median: ', sum(no_def_age) / float(len(no_def_age)) #—Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–µ–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ–¥–∏–∞–Ω—ã –≤ 1000 –≤—ã–±–æ—Ä–∫–∞—Ö \n",
    "print 'with_def_age median: ', sum(with_def_age) / float(len(with_def_age))\n",
    "\n",
    "delta_median_scores_age = map(lambda x: x[0] - x[1], zip(no_def_age, with_def_age)) # –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–Ω–æ—Å—Ç–∏ –º–µ–¥–∏–∞–Ω\n",
    "\n",
    "print 'delta ', sum(delta_median_scores_age) / float(len(delta_median_scores_age)) #—Å—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–æ—Å—Ç—å\n",
    "\n",
    "print \"95% confidence interval for the difference between medians\",  stat_intervals(delta_median_scores_age, 0.05) #–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑ (–ü–ê–†–ê–ú–ï–¢–†–ò–ß–ï–°–ö–ò–ï –ö–†–ò–¢–ï–†–ò–ò)\n",
    "\n",
    "## –ö—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.weightstats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–¥–Ω–æ–≤—ã–±–æ—Ä–æ—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞\n",
    "\n",
    "ùêª0:  —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏ —Ä–∞–≤–Ω–æ mean.\n",
    "\n",
    "ùêª1: –Ω–µ —Ä–∞–≤–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print stats.ttest_1samp(data, mean) #–∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "print \"95%% confidence interval: [%f, %f]\" % zconfint(data) #–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–≤—É—Ö–≤—ã–±–æ—Ä–æ—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞ (–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –≤—ã–±–æ—Ä–∫–∏)\n",
    "\n",
    "ùêª0:  —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–≤—É—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –≤—ã–±–æ—Ä–æ–∫ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ.\n",
    "\n",
    "ùêª1:  –Ω–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(data_1, data_2, equal_var = False) #–∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "cm = CompareMeans(DescrStatsW(data_1), DescrStatsW(data_2)) #—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö\n",
    "print \"95%% confidence interval: [%f, %f]\" % cm.tconfint_diff(usevar='unequal') #–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ —Å—Ä–µ–¥–Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–≤—É—Ö–≤—ã–±–æ—Ä–æ—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞ (–∑–∞–≤–∏—Å–º—ã–µ –≤—ã–±–æ—Ä–∫–∏)\n",
    "\n",
    "ùêª0: —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–≤—É—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –≤—ã–±–æ—Ä–æ–∫ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ.\n",
    "\n",
    "ùêª1: –Ω–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(data_1, data_2) #–∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "print \"95%% confidence interval: [%f, %f]\" % DescrStatsW(data_1 - data_2).tconfint_mean() #–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ —Å—Ä–µ–¥–Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ù–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "–ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤ –≤—ã–±–æ—Ä–∫–∞—Ö —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q –≥—Ä–∞—Ñ–∏–∫\n",
    "%pylab inline\n",
    "pylab.figure(figsize=(12,8))\n",
    "pylab.subplot(2,2,1)\n",
    "stats.probplot(data_1, dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(2,2,2)\n",
    "stats.probplot(data_2, dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ö—Ä–∏—Ç–µ—Ä–∏–π –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞:\n",
    "\n",
    "ùêª0:  –≤—ã–±–æ—Ä–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–ª–µ–Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ\n",
    "\n",
    "ùêª1:  –Ω–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Shapiro-Wilk normality test, W-statistic: %f, p-value: %f\" % stats.shapiro(data_1)\n",
    "print \"Shapiro-Wilk normality test, W-statistic: %f, p-value: %f\" % stats.shapiro(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑ –æ –¥–æ–ª—è—Ö\n",
    "\n",
    "### Z-–∫—Ä–∏—Ç–µ—Ä–∏–π –¥–ª—è –¥–æ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.binom_test(sum(data), n=len(data), p=0.05, alternative='greater') \n",
    "# n - —á–∏—Å–ª–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π\n",
    "# sum(data) - —á–∏—Å–ª–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏—Å—Ö–æ–¥–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-–∫—Ä–∏—Ç–µ—Ä–∏–π –¥–ª—è –¥–≤—É—Ö –¥–æ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from statsmodels.stats.weightstats import *\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   | $X_1$ | $X_2$  \n",
    "  ------------- | -------------|\n",
    "  1  | a | b \n",
    "  0  | c | d \n",
    "  $\\sum$ | $n_1$| $n_2$\n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{a}{n_1}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{b}{n_2}$$\n",
    "\n",
    "\n",
    "$$\\text{–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è }p_1 - p_2\\colon \\;\\; \\hat{p}_1 - \\hat{p}_2 \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}$$\n",
    "\n",
    "$$Z-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: Z({X_1, X_2}) =  \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{P(1 - P)(\\frac{1}{n_1} + \\frac{1}{n_2})}}$$\n",
    "$$P = \\frac{\\hat{p}_1{n_1} + \\hat{p}_2{n_2}}{{n_1} + {n_2}} $$\n",
    "\n",
    "H0: p1=p2\n",
    "\n",
    "H1: p1!=p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_ind(sample1, sample2): #–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è z-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'): # –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Z-–∫—Ä–∏—Ç–µ—Ä–∏–π –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ –¥–æ–ª–µ–π (—Å–≤—è–∑–∞–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $X_1$ \\ $X_2$ | 1| 0 | $\\sum$\n",
    "  ------------- | -------------| -------------| -------------|\n",
    "  1  | e | f | e + f\n",
    "  0  | g | h | g + h\n",
    "  $\\sum$ | e + g| f + h | n  \n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{e + f}{n}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{e + g}{n}$$\n",
    "\n",
    "$$ \\hat{p}_1 - \\hat{p}_2 = \\frac{f - g}{n}$$\n",
    "\n",
    "\n",
    "$$\\text{–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è }p_1 - p_2\\colon \\;\\;  \\frac{f - g}{n} \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{f + g}{n^2} - \\frac{(f - g)^2}{n^3}}$$\n",
    "\n",
    "$$Z-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: Z({X_1, X_2}) = \\frac{f - g}{\\sqrt{f + g - \\frac{(f-g)^2}{n}}}$$\n",
    "\n",
    "\n",
    "H0: p1=p2\n",
    "\n",
    "H1: p1!=p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_rel(sample1, sample2): # –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ z-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–∏ 2—Ö –¥–æ–ª–µ–π\n",
    "    sample = zip(sample1, sample2)\n",
    "    n = len(sample)\n",
    "    \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    return float(f - g) / np.sqrt(f + g - float((f - g)**2) / n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'): # –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑ (–ù–ï–ü–ê–†–ê–ú–ï–¢–†–ò–ß–ï–°–ö–ò–ï –ö–†–ò–¢–ï–†–ò–ò)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " –ö—Ä–∏—Ç–µ—Ä–∏–π | –û–¥–Ω–æ–≤—ã–±–æ—Ä–æ—á–Ω—ã–π | –î–≤—É—Ö–≤—ã–±–æ—Ä–æ—á–Ω—ã–π | –î–≤—É—Ö–≤—ã–±–æ—Ä–æ—á–Ω—ã–π (—Å–≤—è–∑–∞–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏)  \n",
    "  ------------- | -------------| -------------|-------------|\n",
    "  **–ó–Ω–∞–∫–æ–≤**          |$\\times$   |     $ $     | $\\times$ \n",
    "  **–†–∞–Ω–≥–æ–≤—ã–π**        | $\\times$  | $\\times$ | $\\times$  \n",
    "  **–ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–π** | $\\times$  | $\\times$ | $\\times$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "from statsmodels.stats.weightstats import zconfint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ö–†–ò–¢–ï–†–ò–ò –ó–ù–ê–ö–û–í"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö—Ä–∏—Ç–µ—Ä–∏–π –∑–Ω–∞–∫–æ–≤ (–æ–¥–Ω–æ–≤—ã–±–æ—Ä–æ—á–Ω—ã–π)\n",
    "ùêª0: –º–µ–¥–∏–∞–Ω–∞  —Ä–∞–≤–Ω–∞ m0\n",
    "\n",
    "ùêª1: –º–µ–¥–∏–∞–Ω–∞ –Ω–µ —Ä–∞–≤–Ω–∞ m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"M: %d, p-value: %f\" % sign_test(data, m0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö—Ä–∏—Ç–µ—Ä–∏–π –∑–Ω–∞–∫–æ–≤ (–¥–ª—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫)\n",
    "\n",
    "$H_0\\colon P\\left(X_1>X_2\\right)=\\frac1{2},$\n",
    "\n",
    "$H_1\\colon P\\left(X_1>X_2\\right)\\neq\\frac1{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"M: %d, p-value: %f\" % sign_test(data_1 - data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –†–ê–ù–ì–û–í–´–ï –ö–†–ò–¢–ï–†–ò–ò"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö—Ä–∏—Ç–µ—Ä–∏–π –∑–Ω–∞–∫–æ–≤—ã—Ö —Ä–∞–Ω–≥–æ–≤ –í–∏–ª–∫–æ–∫—Å–æ–Ω–∞ (–æ–¥–Ω–æ–≤—ã–±–æ—Ä–æ—á–Ω—ã–π)\n",
    "\n",
    "ùêª0: –º–µ–¥–∏–∞–Ω–∞ —Ä–∞–≤–Ω–∞ m0\n",
    "\n",
    "ùêª1: –º–µ–¥–∏–∞–Ω–∞ –Ω–µ —Ä–∞–≤–Ω–∞ m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(data - m0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–Ω–≥–æ–≤—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ (–¥–ª—è 2—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –≤—ã–±–æ—Ä–æ–∫)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0\\colon F_{X_1}(x) = F_{X_2}(x)$\n",
    "\n",
    "$H_1\\colon F_{X_1}(x) = F_{X_2}(x + \\Delta), \\Delta\\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(data_1, data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö—Ä–∏—Ç–µ—Ä–∏–π –∑–Ω–∞–∫–æ–≤—ã—Ö —Ä–∞–Ω–≥–æ–≤ –í–∏–ª–∫–æ–∫—Å–æ–Ω–∞ (–¥–ª—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫)\n",
    "$H_0\\colon med\\left(X_1-X_2\\right)=0,$\n",
    "\n",
    "$H_1\\colon med\\left(X_1-X_2\\right)\\neq0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(data_1 - data_2)\n",
    "#stats.wilcoxon(data_1, data_2) - —Ç–æ –∂–µ —Å–∞–º–æ–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü–ï–†–ï–°–¢–ê–ù–û–í–û–ß–ù–´–ï –ö–†–ò–¢–ï–†–ò–ò"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π (–æ–¥–Ω–æ–≤—ã–±–æ—Ä–æ—á–Ω—ã–π)\n",
    "ùêª0: —Å—Ä–µ–¥–Ω–µ–µ —Ä–∞–≤–Ω–æ mean\n",
    "\n",
    "ùêª1: —Å—Ä–µ–¥–Ω–µ–µ –Ω–µ —Ä–∞–≤–Ω–æ mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_1sample(sample, mean): #—Ñ—É–Ω–∫—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è T-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    t_stat = sum(map(lambda x: x - mean, sample))\n",
    "    return t_stat\n",
    "\n",
    "def permutation_zero_distr_1sample(sample, mean, max_permutations = None): #—Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω—É–ª–µ–≤–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "    centered_sample = map(lambda x: x - mean, sample)\n",
    "    if max_permutations:\n",
    "        signs_array = set([tuple(x) for x in 2 * np.random.randint(2, size = (max_permutations, \n",
    "                                                                              len(sample))) - 1 ])\n",
    "    else:\n",
    "        signs_array =  itertools.product([-1, 1], repeat = len(sample))\n",
    "    distr = [sum(centered_sample * np.array(signs)) for signs in signs_array]\n",
    "    return distr\n",
    "\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'): #—Ñ—É–Ω–∫—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_1sample(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_distr_1sample(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"p-value: %f\" % permutation_test(data, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π (–¥–ª—è 2—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –≤—ã–±–æ—Ä–æ–∫)\n",
    "$H_0\\colon F_{X_1}(x) = F_{X_2}(x)$\n",
    "\n",
    "$H_1\\colon F_{X_1}(x) = F_{X_2}(x + \\Delta), \\Delta\\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_ind(sample1, sample2): #—Ñ—É–Ω–∫—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è T-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    return np.mean(sample1) - np.mean(sample2)\n",
    "\n",
    "def get_random_combinations(n1, n2, max_combinations): #—Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤\n",
    "    index = range(n1 + n2)\n",
    "    indices = set([tuple(index)])\n",
    "    for i in range(max_combinations - 1):\n",
    "        np.random.shuffle(index)\n",
    "        indices.add(tuple(index))\n",
    "    return [(index[:n1], index[n1:]) for index in indices]\n",
    "\n",
    "def permutation_zero_dist_ind(sample1, sample2, max_combinations = None): #—Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –Ω—É–ª–µ–≤–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "    joined_sample = np.hstack((sample1, sample2))\n",
    "    n1 = len(sample1)\n",
    "    n = len(joined_sample)\n",
    "    \n",
    "    if max_combinations:\n",
    "        indices = get_random_combinations(n1, len(sample2), max_combinations)\n",
    "    else:\n",
    "        indices = [(list(index), filter(lambda i: i not in index, range(n))) \\\n",
    "                    for index in itertools.combinations(range(n), n1)]\n",
    "    \n",
    "    distr = [joined_sample[list(i[0])].mean() - joined_sample[list(i[1])].mean() \\\n",
    "             for i in indices]\n",
    "    return distr\n",
    "\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):  #—Ñ—É–Ω–∫—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_ind(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_dist_ind(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"p-value: %f\" % permutation_test(data_1, data_2, max_permutations = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π (–¥–ª—è 2—Ö —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫)\n",
    "$H_0\\colon \\mathbb{E}(X_1 - X_2) = 0$\n",
    "\n",
    "$H_1\\colon \\mathbb{E}(X_1 - X_2) \\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_1sample(sample, mean):\n",
    "    t_stat = sum(map(lambda x: x - mean, sample))\n",
    "    return t_stat\n",
    "def permutation_zero_distr_1sample(sample, mean, max_permutations = None):\n",
    "    centered_sample = map(lambda x: x - mean, sample)\n",
    "    if max_permutations:\n",
    "        signs_array = set([tuple(x) for x in 2 * np.random.randint(2, size = (max_permutations, \n",
    "                                                                              len(sample))) - 1 ])\n",
    "    else:\n",
    "        signs_array =  itertools.product([-1, 1], repeat = len(sample))\n",
    "    distr = [sum(centered_sample * np.array(signs)) for signs in signs_array]\n",
    "    return distr\n",
    "\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_1sample(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_distr_1sample(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"p-value: %f\" % permutation_test(data_1 - data_2, 0., max_permutations = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –°—Ç—å—é–¥–µ–Ω—Ç–∞ –∏ –°–ø–∏—Ä–º–µ–Ω–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.corr() #—Å—Ç—å—é–¥–µ–Ω—Ç\n",
    "dt.corr(method='spearman') #—Å–ø–∏—Ä–º–µ–Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, p = pearsonr(dt[col1], dt[col2]) #—Ä–∞—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–∏—Ä—Å–æ–Ω–∞ —Å —É—Ä–æ–≤–Ω–µ–º –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ú—ç—Ç—å—é—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = np.array([a,b],[c,d]) #—Ç–∞–±–ª–∏—Ü–∞ —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "def Metus_cor(a,b,c,d):\n",
    "    return (a*d-b*c)/float(np.sqrt((a+b)*(a+c)*(d+b)*(c+d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ú—ç—Ç—å—é—Å–∞ (–∫—Ä–∏—Ç–µ—Ä–∏–π —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "obs = np.array([[a,b],[c,d]]) #—Ç–∞–±–ª–∏—Ü–∞ —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö\n",
    "chi2, p, dof, ex = chi2_contingency(obs)\n",
    "print 'stat=',chi2 #–∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "print 'p=', p #–¥–æ—Å—Ç–∏–≥–∞–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "print 'dof=', dof #—á–∏—Å–ª–æ —Å—Ç–µ–ø–µ–Ω–µ–π —Å–≤–æ–±–æ–¥—ã\n",
    "print 'ex=', ex #–æ–∂–∏–¥–∞–µ–º—ã–µ —á–∞—Å—Ç–æ—Ç—ã –æ–±—ã—Ç–∏–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö—Ä–∏—Ç–µ—Ä–∏–π —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "xi_2_f = chisquare(mas1.reshape(),mas2.reshape(), ddof=0) #–≥–∏–ø–æ—Ç–µ–∑–∞ mas1 —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ —Ç–∞–∫–æ–º—É –∂–µ –∑–∞–∫–æ–Ω—É, —á—Ç–æ –∏  mas2\n",
    "xi_2_f #–≤—ã–¥–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–º–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–ø—Ä–∞–≤–∫–∏ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É\n",
    "### –ú–µ—Ç–æ–¥ –•–æ–ª–º–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests \n",
    "reject, p_corrected, a1, a2 = multipletests(df.p, alpha = 0.05, method = 'holm') \n",
    "# df.p - —Å—Ç–æ–ª–±–µ—Ü df –≤ –∫–æ—Ç–æ—Ä–æ–º –∑–∞–ø–∏—Å–∞–Ω—ã —É—Ä–æ–≤–Ω–∏ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –≥–∏–ø–æ—Ç–µ–∑\n",
    "# alpha - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å–æ–≤–µ—Ä—à–∏—Ç—å —Ö–æ—Ç—è –±—ã 1  –æ—à–∏–±–∫—É 1 —Ä–æ–¥–∞\n",
    "# reject  - —Ä–µ—à–µ–Ω–∏–µ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å(true) –≥–∏–ø–æ—Ç–µ–∑—É –∏–ª–∏ –Ω–µ—Ç(false)\n",
    "# p_corrected - —Å–∫—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú–µ—Ç–æ–¥ –ë–µ–Ω–¥–∂–∞–º–∏–Ω–∏-–•–æ—Ö–±–µ—Ä–≥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(df.p, alpha = 0.05, method = 'fdr_bh') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
