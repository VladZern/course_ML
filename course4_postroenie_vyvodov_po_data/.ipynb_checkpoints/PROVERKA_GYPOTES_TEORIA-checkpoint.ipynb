{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Доверительный интервал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z-интервал\n",
    "\n",
    "Допустим, нам откуда-то известно, что дисперсия auc_scores $\\sigma^2=0.25$. Построим доверительные интервалы для средних вида $$\\bar{X}_n \\pm z_{1-\\frac{\\alpha}{2}} \\frac{\\sigma}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"95%% confidence interval\", _zconfint_generic(mean,sqrt(0.25/n), alpha = 0.05, 'two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-интервал\n",
    "\n",
    "Вместо гипотетической теоретической дисперсии $\\sigma^2$, которую мы на самом деле в данном случае не знаем, используем выборочные дисперсии, и построим доверительные интервалы вида $$\\bar{X}_n \\pm t_{1-\\frac{\\alpha}{2}} \\frac{S}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"mean 95%% confidence interval\", _tconfint_generic(mean, std/sqrt(n), dof= n - 1, alpha=0.05, 'two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Доверительные интервалы для доли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доверительный интервал на основе нормального распределения\n",
    "\n",
    "$$\\hat{p}\\pm z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}\\left(1-\\hat{p}\\right)}{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_interval = proportion_confint(sum(sample), len(sample), method = 'normal')\n",
    "print 'normal_interval [%f, %f]' % (normal_interval[0], normal_interval[1]) \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доверительный интервал Уилсона\n",
    "\n",
    "$$\\frac1{ 1 + \\frac{z^2}{n} } \\left( \\hat{p} + \\frac{z^2}{2n} \\pm z \\sqrt{ \\frac{ \\hat{p}\\left(1-\\hat{p}\\right)}{n} + \\frac{\n",
    "z^2}{4n^2} } \\right), \\;\\; z \\equiv z_{1-\\frac{\\alpha}{2}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilson_interval = proportion_confint(sum(sample), len(sample), method = 'wilson')\n",
    "print 'wilson_interval [%f, %f]' % (wilson_interval[0], wilson_interval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Размер выборки для интервала заданной ширины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import samplesize_confint_proportion\n",
    "import numpy as np\n",
    "n_samples = int(np.ceil(samplesize_confint_proportion(sample.mean(), width/2)))\n",
    "# n_samples - размер выборки\n",
    "# width - ширина доверительного интервала"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Доверительные интервалы для двух долей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.weightstats import *\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доверительный интервал для разности долей (независимые выборки)\n",
    "\n",
    " $..$ | $X_1$ | $X_2$  \n",
    " ------------- | ------------- | -------------|\n",
    "  1  | a | b \n",
    "  0  | c | d \n",
    "  $\\sum$ | $n_1$| $n_2$\n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{a}{n_1}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{b}{n_2}$$\n",
    "\n",
    "\n",
    "$$\\text{Доверительный интервал для }p_1 - p_2\\colon \\;\\; \\hat{p}_1 - \\hat{p}_2 \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_confint_diff_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)   \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)\n",
    "print \"confidence interval: [%f, %f]\" % proportions_confint_diff_ind(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доверительный интервал для разности долей (связанные выборки)\n",
    "\n",
    "$X_1$ \\ $X_2$ | 1| 0 | $\\sum$\n",
    "  ------------- | -------------| -------------| -------------|\n",
    "  1  | e | f | e + f\n",
    "  0  | g | h | g + h\n",
    "  $\\sum$ | e + g| f + h | n  \n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{e + f}{n}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{e + g}{n}$$\n",
    "\n",
    "$$ \\hat{p}_1 - \\hat{p}_2 = \\frac{f - g}{n}$$\n",
    "\n",
    "\n",
    "$$\\text{Доверительный интервал для }p_1 - p_2\\colon \\;\\;  \\frac{f - g}{n} \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{f + g}{n^2} - \\frac{(f - g)^2}{n^3}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_confint_diff_rel(sample1, sample2, alpha = 0.05):\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    sample = zip(sample1, sample2)\n",
    "    n = len(sample)\n",
    "        \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    left_boundary = float(f - g) / n  - z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    right_boundary = float(f - g) / n  + z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    return (left_boundary, right_boundary)\n",
    "print \"confidence interval: [%f, %f]\" % proportions_confint_diff_rel(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Доверительные интервалы на основе bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples): #функция генерации n_samples выборок из data, методом bootstrap\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "def stat_intervals(stat, alpha): #функция генерации доверительного интервала для статисики\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_def_age = map(np.median, get_bootstrap_samples(df[df.default == 0].AGE.values, 1000)) #генерируем выборки и находим медианы\n",
    "with_def_age = map(np.median, get_bootstrap_samples(df[df.default == 1].AGE.values, 1000))\n",
    "\n",
    "print 'no_def_age median: ', sum(no_def_age) / float(len(no_def_age)) #считаем среденее значение медианы в 1000 выборках \n",
    "print 'with_def_age median: ', sum(with_def_age) / float(len(with_def_age))\n",
    "\n",
    "delta_median_scores_age = map(lambda x: x[0] - x[1], zip(no_def_age, with_def_age)) # оценка разности медиан\n",
    "\n",
    "print 'delta ', sum(delta_median_scores_age) / float(len(delta_median_scores_age)) #средняя разность\n",
    "\n",
    "print \"95% confidence interval for the difference between medians\",  stat_intervals(delta_median_scores_age, 0.05) #доверительный интервал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка гипотез (ПАРАМЕТРИЧЕСКИЕ КРИТЕРИИ)\n",
    "\n",
    "## Критерий Стьюдента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.weightstats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Одновыборочный критерий Стьюдента\n",
    "\n",
    "𝐻0:  среднее значение выборки равно mean.\n",
    "\n",
    "𝐻1: не равно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print stats.ttest_1samp(data, mean) #значение статистики и уровень значимости\n",
    "print \"95%% confidence interval: [%f, %f]\" % zconfint(data) #доверительный интервал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Двухвыборочный критерий Стьюдента (независимые выборки)\n",
    "\n",
    "𝐻0:  средние значения двух независимых выборок одинаковые.\n",
    "\n",
    "𝐻1:  не одинаковы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(data_1, data_2, equal_var = False) #значение статистики и уровень значимости\n",
    "cm = CompareMeans(DescrStatsW(data_1), DescrStatsW(data_2)) #сравнение средних\n",
    "print \"95%% confidence interval: [%f, %f]\" % cm.tconfint_diff(usevar='unequal') #доверительный интервал для разности средних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Двухвыборочный критерий Стьюдента (зависмые выборки)\n",
    "\n",
    "𝐻0: средние значения двух независимых выборок одинаковые.\n",
    "\n",
    "𝐻1: не одинаковы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(data_1, data_2) #значение статистики и уровень значимости\n",
    "print \"95%% confidence interval: [%f, %f]\" % DescrStatsW(data_1 - data_2).tconfint_mean() #доверительный интервал для разности средних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормальность выборки\n",
    "\n",
    "Проверка, что распределения в выборках существенно не отличаются от нормальных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q график\n",
    "%pylab inline\n",
    "pylab.figure(figsize=(12,8))\n",
    "pylab.subplot(2,2,1)\n",
    "stats.probplot(data_1, dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(2,2,2)\n",
    "stats.probplot(data_2, dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Критерий Шапиро-Уилка:\n",
    "\n",
    "𝐻0:  выборка распредлена нормально\n",
    "\n",
    "𝐻1:  не нормально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Shapiro-Wilk normality test, W-statistic: %f, p-value: %f\" % stats.shapiro(data_1)\n",
    "print \"Shapiro-Wilk normality test, W-statistic: %f, p-value: %f\" % stats.shapiro(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка гипотез о долях\n",
    "\n",
    "### Z-критерий для доли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.binom_test(sum(data), n=len(data), p=0.05, alternative='greater') \n",
    "# n - число испытаний\n",
    "# sum(data) - число положительных исходов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-критерий для двух долей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from statsmodels.stats.weightstats import *\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   | $X_1$ | $X_2$  \n",
    "  ------------- | -------------|\n",
    "  1  | a | b \n",
    "  0  | c | d \n",
    "  $\\sum$ | $n_1$| $n_2$\n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{a}{n_1}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{b}{n_2}$$\n",
    "\n",
    "\n",
    "$$\\text{Доверительный интервал для }p_1 - p_2\\colon \\;\\; \\hat{p}_1 - \\hat{p}_2 \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}$$\n",
    "\n",
    "$$Z-статистика: Z({X_1, X_2}) =  \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{P(1 - P)(\\frac{1}{n_1} + \\frac{1}{n_2})}}$$\n",
    "$$P = \\frac{\\hat{p}_1{n_1} + \\hat{p}_2{n_2}}{{n_1} + {n_2}} $$\n",
    "\n",
    "H0: p1=p2\n",
    "\n",
    "H1: p1!=p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_ind(sample1, sample2): #вычисление значения z-статистики\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'): # вычисление уровня значимости\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Z-критерий для разности долей (связанные выборки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $X_1$ \\ $X_2$ | 1| 0 | $\\sum$\n",
    "  ------------- | -------------| -------------| -------------|\n",
    "  1  | e | f | e + f\n",
    "  0  | g | h | g + h\n",
    "  $\\sum$ | e + g| f + h | n  \n",
    "  \n",
    "$$ \\hat{p}_1 = \\frac{e + f}{n}$$\n",
    "\n",
    "$$ \\hat{p}_2 = \\frac{e + g}{n}$$\n",
    "\n",
    "$$ \\hat{p}_1 - \\hat{p}_2 = \\frac{f - g}{n}$$\n",
    "\n",
    "\n",
    "$$\\text{Доверительный интервал для }p_1 - p_2\\colon \\;\\;  \\frac{f - g}{n} \\pm z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{f + g}{n^2} - \\frac{(f - g)^2}{n^3}}$$\n",
    "\n",
    "$$Z-статистика: Z({X_1, X_2}) = \\frac{f - g}{\\sqrt{f + g - \\frac{(f-g)^2}{n}}}$$\n",
    "\n",
    "\n",
    "H0: p1=p2\n",
    "\n",
    "H1: p1!=p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_rel(sample1, sample2): # вычисление z-статистики для разности 2х долей\n",
    "    sample = zip(sample1, sample2)\n",
    "    n = len(sample)\n",
    "    \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    return float(f - g) / np.sqrt(f + g - float((f - g)**2) / n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'): # вычисление уровня значимости\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка гипотез (НЕПАРАМЕТРИЧЕСКИЕ КРИТЕРИИ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Критерий | Одновыборочный | Двухвыборочный | Двухвыборочный (связанные выборки)  \n",
    "  ------------- | -------------| -------------|-------------|\n",
    "  **Знаков**          |$\\times$   |     $ $     | $\\times$ \n",
    "  **Ранговый**        | $\\times$  | $\\times$ | $\\times$  \n",
    "  **Перестановочный** | $\\times$  | $\\times$ | $\\times$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "from statsmodels.stats.weightstats import zconfint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# КРИТЕРИИ ЗНАКОВ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий знаков (одновыборочный)\n",
    "𝐻0: медиана  равна m0\n",
    "\n",
    "𝐻1: медиана не равна m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"M: %d, p-value: %f\" % sign_test(data, m0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий знаков (для связанных выборок)\n",
    "\n",
    "$H_0\\colon P\\left(X_1>X_2\\right)=\\frac1{2},$\n",
    "\n",
    "$H_1\\colon P\\left(X_1>X_2\\right)\\neq\\frac1{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"M: %d, p-value: %f\" % sign_test(data_1 - data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РАНГОВЫЕ КРИТЕРИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий знаковых рангов Вилкоксона (одновыборочный)\n",
    "\n",
    "𝐻0: медиана равна m0\n",
    "\n",
    "𝐻1: медиана не равна m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(data - m0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ранговый критерий Манна-Уитни (для 2х независимых выборок)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0\\colon F_{X_1}(x) = F_{X_2}(x)$\n",
    "\n",
    "$H_1\\colon F_{X_1}(x) = F_{X_2}(x + \\Delta), \\Delta\\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(data_1, data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий знаковых рангов Вилкоксона (для связанных выборок)\n",
    "$H_0\\colon med\\left(X_1-X_2\\right)=0,$\n",
    "\n",
    "$H_1\\colon med\\left(X_1-X_2\\right)\\neq0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(data_1 - data_2)\n",
    "#stats.wilcoxon(data_1, data_2) - то же самое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПЕРЕСТАНОВОЧНЫЕ КРИТЕРИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перестановочный критерий (одновыборочный)\n",
    "𝐻0: среднее равно mean\n",
    "\n",
    "𝐻1: среднее не равно mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_1sample(sample, mean): #функция вычисления T-статистики\n",
    "    t_stat = sum(map(lambda x: x - mean, sample))\n",
    "    return t_stat\n",
    "\n",
    "def permutation_zero_distr_1sample(sample, mean, max_permutations = None): #функция построения нулевого распределения\n",
    "    centered_sample = map(lambda x: x - mean, sample)\n",
    "    if max_permutations:\n",
    "        signs_array = set([tuple(x) for x in 2 * np.random.randint(2, size = (max_permutations, \n",
    "                                                                              len(sample))) - 1 ])\n",
    "    else:\n",
    "        signs_array =  itertools.product([-1, 1], repeat = len(sample))\n",
    "    distr = [sum(centered_sample * np.array(signs)) for signs in signs_array]\n",
    "    return distr\n",
    "\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'): #функция вычисления уровня значимости\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_1sample(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_distr_1sample(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"p-value: %f\" % permutation_test(data, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перестановочный критерий (для 2х независимых выборок)\n",
    "$H_0\\colon F_{X_1}(x) = F_{X_2}(x)$\n",
    "\n",
    "$H_1\\colon F_{X_1}(x) = F_{X_2}(x + \\Delta), \\Delta\\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_ind(sample1, sample2): #функция вычисления T-статистики\n",
    "    return np.mean(sample1) - np.mean(sample2)\n",
    "\n",
    "def get_random_combinations(n1, n2, max_combinations): #функция генерирования индексов\n",
    "    index = range(n1 + n2)\n",
    "    indices = set([tuple(index)])\n",
    "    for i in range(max_combinations - 1):\n",
    "        np.random.shuffle(index)\n",
    "        indices.add(tuple(index))\n",
    "    return [(index[:n1], index[n1:]) for index in indices]\n",
    "\n",
    "def permutation_zero_dist_ind(sample1, sample2, max_combinations = None): #функция построения нулевого распределения\n",
    "    joined_sample = np.hstack((sample1, sample2))\n",
    "    n1 = len(sample1)\n",
    "    n = len(joined_sample)\n",
    "    \n",
    "    if max_combinations:\n",
    "        indices = get_random_combinations(n1, len(sample2), max_combinations)\n",
    "    else:\n",
    "        indices = [(list(index), filter(lambda i: i not in index, range(n))) \\\n",
    "                    for index in itertools.combinations(range(n), n1)]\n",
    "    \n",
    "    distr = [joined_sample[list(i[0])].mean() - joined_sample[list(i[1])].mean() \\\n",
    "             for i in indices]\n",
    "    return distr\n",
    "\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):  #функция вычисления уровня значимости\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_ind(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_dist_ind(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"p-value: %f\" % permutation_test(data_1, data_2, max_permutations = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перестановочный критерий (для 2х связанных выборок)\n",
    "$H_0\\colon \\mathbb{E}(X_1 - X_2) = 0$\n",
    "\n",
    "$H_1\\colon \\mathbb{E}(X_1 - X_2) \\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_1sample(sample, mean):\n",
    "    t_stat = sum(map(lambda x: x - mean, sample))\n",
    "    return t_stat\n",
    "def permutation_zero_distr_1sample(sample, mean, max_permutations = None):\n",
    "    centered_sample = map(lambda x: x - mean, sample)\n",
    "    if max_permutations:\n",
    "        signs_array = set([tuple(x) for x in 2 * np.random.randint(2, size = (max_permutations, \n",
    "                                                                              len(sample))) - 1 ])\n",
    "    else:\n",
    "        signs_array =  itertools.product([-1, 1], repeat = len(sample))\n",
    "    distr = [sum(centered_sample * np.array(signs)) for signs in signs_array]\n",
    "    return distr\n",
    "\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_1sample(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_distr_1sample(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"p-value: %f\" % permutation_test(data_1 - data_2, 0., max_permutations = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Корреляции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корреляция Стьюдента и Спирмена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.corr() #стьюдент\n",
    "dt.corr(method='spearman') #спирмен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, p = pearsonr(dt[col1], dt[col2]) #расчет корреляции пирсона с уровнем значимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корреляция Мэтьюса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = np.array([a,b],[c,d]) #таблица сопряженности бинарных признаков\n",
    "def Metus_cor(a,b,c,d):\n",
    "    return (a*d-b*c)/float(np.sqrt((a+b)*(a+c)*(d+b)*(c+d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка гипотезы значимости корреляции Мэтьюса (критерий хи-квадрат)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "obs = np.array([[a,b],[c,d]]) #таблица сопряженности бинарных признаков или категориальных\n",
    "chi2, p, dof, ex = chi2_contingency(obs)\n",
    "print 'stat=',chi2 #значение статистики\n",
    "print 'p=', p #достигаемый уровень значимости\n",
    "print 'dof=', dof #число степеней свободы\n",
    "print 'ex=', ex #ожидаемые частоты обытий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий хи-квадрат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "xi_2_f = chisquare(mas1.reshape(),mas2.reshape(), ddof=0) #гипотеза mas1 распределен по такому же закону, что и  mas2\n",
    "xi_2_f #выдает статистику и уровень значмости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Множественная проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поправки на множественную проверку\n",
    "### Метод Холма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests \n",
    "reject, p_corrected, a1, a2 = multipletests(df.p, alpha = 0.05, method = 'holm') \n",
    "# df.p - столбец df в котором записаны уровни значимости гипотез\n",
    "# alpha - вероятности совершить хотя бы 1  ошибку 1 рода\n",
    "# reject  - решение отвергнуть(true) гипотезу или нет(false)\n",
    "# p_corrected - скректированные уровни значимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод Бенджамини-Хохберга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject, p_corrected, a1, a2 = multipletests(df.p, alpha = 0.05, method = 'fdr_bh') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
